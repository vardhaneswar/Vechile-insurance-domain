# Vechile-insurance-domain
Project on vechile insurance domain
ğŸš— Vehicle Data Classification â€“ End-to-End MLOps Project

Production-Grade MLOps | MongoDB | AWS | Docker | GitHub Actions | FastAPI

<p align="center">














</p>

This repository contains a real-world, end-to-end MLOps project demonstrating how to build, train, evaluate, version, and deploy ML models using a complete cloud-native pipeline.

The workflow includes:
âœ” Project scaffolding
âœ” MongoDB ingestion
âœ” Automated ML pipeline
âœ” AWS S3 model registry
âœ” Dockerized FastAPI service
âœ” Full CI/CD pipeline using GitHub Actions + EC2 self-hosted runner
âœ” Production deployment on AWS

ğŸ—ï¸ System Architecture
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚        Developer         â”‚
                                    â”‚(Local Machine / VSCode)  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚ 1. Project Template   â”‚
                                      â”‚ setup.py + pyproject  â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚          Local ML Pipeline (src/)        â”‚
                           â”‚ Ingestion â†’ Validation â†’ Transformation  â”‚
                           â”‚   â†’ Training â†’ Evaluation â†’ Pusher       â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚    MongoDB Atlas     â”‚
                                  â”‚ Raw + Cleaned Data   â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚   AWS S3 Bucket      â”‚
                                  â”‚   Model Registry     â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚         GitHub CI/CD Pipeline              â”‚
                         â”‚ (Build â†’ Test â†’ Push Image â†’ Deploy to EC2)â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Docker Image (ECR)   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚      AWS EC2 Server    â”‚
                               â”‚ Runs Docker Container  â”‚
                               â”‚ Exposes Port :5080     â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚  FastAPI Web App   â”‚
                                 â”‚    /predict        â”‚
                                 â”‚    /train          â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸŒŸ Features

Template-based project structure

Local package installation using setup.py + pyproject.toml

MongoDB Atlas integration for raw data ingestion

Fully modular ML pipeline (Ingestion â†’ Validation â†’ Transformation â†’ Training â†’ Evaluation â†’ Pushing)

AWS S3 model registry

Dockerization

GitHub Actions CI/CD

Self-hosted EC2 runner

Production deployment on AWS EC2

FastAPI UI with prediction and training endpoints

ğŸ—ï¸ 1. Project Setup
Create project structure
python template.py

Create & activate virtual environment
conda create -n vehicle python=3.10 -y
conda activate vehicle
pip install -r requirements.txt
pip list

Local package imports

Supported using:

setup.py

pyproject.toml

ğŸƒ 2. MongoDB Atlas Setup

Create MongoDB Atlas account

Create project â†’ M0 cluster

Add DB user

Add network access 0.0.0.0/0

Copy connection URL

Load dataset via Jupyter Notebook

View records in Atlas â†’ Collections

Set MongoDB URL

PowerShell

$env:MONGODB_URL="mongodb+srv://..."


Bash

export MONGODB_URL="mongodb+srv://..."


Add artifact/ to .gitignore.

ğŸ“¥ 3. Data Ingestion Pipeline

Add constants

Configure DB connection

Create ingestion component

Convert MongoDB â†’ DataFrame

Save raw & split data into artifacts

Run:

python demo.py

ğŸ” 4. Data Validation, Transformation & Model Trainer
Data Validation

Schema checking (columns, types)

Missing values check

Dataset integrity

Data Transformation

Preprocessing pipelines

Feature engineering

Save transformers + metadata

Model Trainer

Train multiple models

Select best one

Save artifacts

â˜ï¸ 5. AWS Setup (IAM, S3, Env)
Create IAM User

Region: us-east-1

Policy: AdministratorAccess

Generate Access Key + Secret Key

Export AWS credentials
export AWS_ACCESS_KEY_ID="..."
export AWS_SECRET_ACCESS_KEY="..."

Update constants
MODEL_EVALUATION_CHANGED_THRESHOLD_SCORE = 0.02
MODEL_BUCKET_NAME = "my-model-mlopsproj"
MODEL_PUSHER_S3_KEY = "model-registry"

Create S3 bucket
my-model-mlopsproj
us-east-1

Add S3 utility modules

aws_storage/

entity/s3_estimator.py

ğŸ§ª 6. Model Evaluation & Model Pusher

Evaluate new model vs existing S3 model

If improved, push model to registry

Logs versioning + promotion flow

âš¡ 7. Prediction Pipeline + FastAPI App

Build prediction_pipeline.py

Create app.py

Add static/ and templates/

Run locally:

python app.py


Endpoints:

/predict
/train

ğŸ³ 8. Docker + CI/CD Deployments
Dockerize the application

Create:

Dockerfile

.dockerignore

GitHub Actions workflow

Located at:

.github/workflows/aws.yaml

AWS ECR Setup

Repository:

vehicleproj

AWS EC2 Setup

Ubuntu 24.04

t2.medium

30GB storage

Allow HTTP/HTTPS

Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu
newgrp docker

ğŸ›°ï¸ 9. Connect GitHub â†’ EC2 (Self-Hosted Runner)

GitHub â†’ Settings â†’ Actions â†’ Runners â†’ Add Runner

Run all commands on EC2:

Download

Configure

Run

Add repo secrets:

AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
AWS_DEFAULT_REGION
ECR_REPO

ğŸš€ 10. Deployment
Open port 5080 in EC2:
Custom TCP | 5080 | 0.0.0.0/0

Access app:
http://<EC2-IP>:5080


Training:

/training

ğŸ› ï¸ Tech Stack
Machine Learning & Python

Python 3.10

Pandas, NumPy, Sklearn

Custom pipelines + artifacts

Jinja2, FastAPI

Data Engineering

MongoDB Atlas

Data validation with schema

Data ingestion pipelines

Cloud & DevOps

AWS EC2

AWS S3

AWS ECR

IAM

Docker

GitHub Actions

Self-hosted Runner

ğŸ“Œ Pipeline Overview
Template â†’ Setup â†’ MongoDB â†’ Ingestion â†’ Validation â†’ Transformation â†’ 
Trainer â†’ Evaluation â†’ S3 â†’ Docker â†’ CI/CD â†’ EC2 â†’ FastAPI App